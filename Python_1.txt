Quetions 1 # Load necessary libraries
library(ggplot2)
library(caret)

# question 1.1: Load the mtcars dataset into a data frame
data(mtcars)
df <- mtcars

# question 2.1: Check the head of the mtcars data frame
head(df)

# question 3.1: Explore the presence of missing data in the dataset
anyNA(df)

# question 4.1: Visualize some of the data using ggplot2 and bar plots
ggplot(df, aes(x = factor(cyl), fill = factor(cyl))) +
  geom_bar(alpha = 0.7) +
  labs(title = "Number of Cars by Cylinders", x = "Number of Cylinders", y = "Count") +
  theme_minimal()

# question 5.1: Visualize the distribution of other features in the mtcars dataset
ggplot(df, aes(x = wt)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  labs(title = "Distribution of Car Weights", x = "Weight (1000 lbs)", y = "Frequency") +
  theme_minimal()

# question 6.1: Perform data cleaning, if necessary, by addressing missing values or outliers

df <- df[, c("cyl", "wt", "am", "gear", "carb")]

# question 7.1: Select the relevant columns for training or analysis


# question 8.1: Train a logistic regression model on the selected columns
# Predict 'am' (automatic/manual transmission) using the selected features
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(df$am, p = .7, list = FALSE)
trainData <- df[trainIndex,]
testData <- df[-trainIndex,]

# question 9.1: Split the dataset into training and testing sets
# Already done in Step 8

# question 10.1: Retrain the logistic regression model on the training set and evaluate its performance on the test set
model <- glm(am ~ cyl + wt + gear + carb, data = trainData, family = binomial)

# question 11.1: Calculate prediction accuracy, misclassification error, and confusion matrix
predicted <- predict(model, testData, type = "response")
predicted_class <- ifelse(predicted > 0.5, 1, 0)
conf_matrix <- confusionMatrix(factor(predicted_class), factor(testData$am))

# question 12.1: Analyze the fitted values or predictions from the logistic regression model
fitted_values <- fitted(model)

# question 13.1: Perform any additional analysis or visualization
# Visualize the confusion matrix
conf_matrix$table
conf_matrix$overall["Accuracy"]
conf_matrix$byClass["Sensitivity"]
conf_matrix$byClass["Specificity"]

# Visualize the predicted probabilities
ggplot(testData, aes(x = predicted, fill = factor(am))) +
  geom_histogram(binwidth = 0.1, alpha = 0.7, position = 'identity') +
  labs(title = "Predicted Probabilities of Transmission Type", x = "Predicted Probability", y = "Count") +
  theme_minimal()



Quetion 2

1.Split the dataset into training and testing sets, with a 70/30 ratio.
# Load necessary libraries
library(caret)
library(class)
library(e1071)
library(rpart)
library(rpart.plot)

# Load the mtcars dataset
data(mtcars)

# Add a binary column 'mpg_category' where mpg > 20 is considered high (1) and <= 20 is low (0)
mtcars$mpg_category <- ifelse(mtcars$mpg > 20, 1, 0)

# Split the dataset into training and testing sets (70/30 ratio)
set.seed(123)
trainIndex <- createDataPartition(mtcars$mpg_category, p = 0.7, list = FALSE)
trainData <- mtcars[trainIndex, ]
testData <- mtcars[-trainIndex, ]

# Remove the 'mpg' column as it is the target variable
trainData$mpg <- NULL
testData$mpg <- NULL


 2.Apply the K-nearest neighbors (KNN) algorithm with k=3 to classify the cars as high or low mileage.
# KNN Model
k <- 3
knn_pred <- knn(train = trainData[, -ncol(trainData)], test = testData[, -ncol(testData)], cl = trainData$mpg_category, k = k)


 3.Calculate the confusion matrix, sum of squared errors (SSE), and accuracy for the KNN model.
# Confusion matrix for KNN
knn_conf_matrix <- confusionMatrix(knn_pred, factor(testData$mpg_category))

# Calculate SSE for KNN
knn_sse <- sum((as.numeric(knn_pred) - 1 - testData$mpg_category)^2)

# KNN Accuracy
knn_accuracy <- knn_conf_matrix$overall['Accuracy']


 4.Use the Support Vector Machine (SVM) algorithm to classify the cars as high or low mileage. 
# SVM Model
svm_model <- svm(mpg_category ~ ., data = trainData, kernel = "linear", cost = 1)

# Predictions with SVM
svm_pred <- predict(svm_model, testData)

     
 5.Calculate the confusion matrix, sum of squared errors (SSE), and accuracy for the SVM model.
# Confusion matrix for SVM
svm_conf_matrix <- confusionMatrix(factor(svm_pred), factor(testData$mpg_category))

# Calculate SSE for SVM
svm_sse <- sum((as.numeric(svm_pred) - 1 - testData$mpg_category)^2)

# SVM Accuracy
svm_accuracy <- svm_conf_matrix$overall['Accuracy']


 6.Build a decision tree model to predict the mileage category.
# Decision Tree Model
tree_model <- rpart(mpg_category ~ ., data = trainData, method = "class")

 7.Visualize the decision tree
# Visualize the decision tree
rpart.plot(tree_model)
.

 8.Calculate the confusion matrix, sum of squared errors (SSE), and accuracy for the decision tree model
# Predictions with Decision Tree
tree_pred <- predict(tree_model, testData, type = "class")

# Confusion matrix for Decision Tree
tree_conf_matrix <- confusionMatrix(tree_pred, factor(testData$mpg_category))

# Calculate SSE for Decision Tree
tree_sse <- sum((as.numeric(tree_pred) - 1 - testData$mpg_category)^2)

# Decision Tree Accuracy
tree_accuracy <- tree_conf_matrix$overall['Accuracy']
 
